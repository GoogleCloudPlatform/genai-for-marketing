{"cells":[{"cell_type":"code","execution_count":null,"id":"359697d5","metadata":{"id":"359697d5"},"outputs":[],"source":["# Copyright 2023 Google LLC\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"attachments":{},"cell_type":"markdown","id":"a92dd084","metadata":{},"source":["# News summarization with LangChain agents and Vertex AI PaLM text models\n","\n","## Overview\n","\n","It is a very common practice in real-world business scenarios to integrate Large Language Models (LLMs) with external sources of knowledge or applications. In a groundbreaking paper titled [Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf), Google Research and Princeton University introduced a paradigm - ReAct -  that combines reasoning and acting with LLMs by allowing models to interact with external environments to gather additional information.\n","\n","[LangChain](https://python.langchain.com/en/latest/index.html) is a framework that allows you to create applications powered by language models. It includes extensive support for [agents](https://python.langchain.com/en/latest/modules/agents.html) based on the ReAct concepts. LangChain agents use [tools](https://python.langchain.com/en/latest/modules/agents/tools.html) to interact with external systems. A tool is a component that performs a specific task, such as retrieving data from an external search engine. LangChain includes a number of predefined tools, such as tools for interacting with Google Search, Wikipedia, ArXiv, SQL databases, and many more. You can also define your own tools.\n","\n","This notebook illustrates how to use LangChain agents with Vertex AI PaLM text models and custom tools. You will build an agent that can help you discover the most popular Google Search terms and analyze news articles related to those terms. An agent like that could be beneficial in a variety of business situations, including marketing, political analysis, and more.\n","\n","The custom tools you will develop will give the agent access to information from the [Google Trends dataset](https://pantheon.corp.google.com/marketplace/product/bigquery-public-datasets/google-search-trends?project=jk-mlops-dev) and [the GDELT database](https://www.gdeltproject.org/). \n","The Google Trends dataset contains the top 25 overall and top 25 rising queries from Google Trends in the past 30 days. The dataset is hosted on Google BigQuery as part of the Google Cloud Datasets initiative.\n","\n","The GDELT Project, which is supported by [Google Jigsaw](https://jigsaw.google.com/), monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages. The GDELT database is free to use and accessible via a variety of interfaces, including Google BigQuery and the REST API. In this notebook, we will be using the REST API.\n","\n","The notebook is structured as follows:\n","- You will begin by installing the necessary packages and configuring your GCP environment.\n","- Next, you will define and test the custom LangChain tools around the Google Trends dataset and the GDEL API.\n","- Finally, you will experiment with using the tools with a few different types of LangChain agents."]},{"attachments":{},"cell_type":"markdown","id":"c2661da7","metadata":{},"source":["## Install pre-requisites\n","Install the following python packages."]},{"cell_type":"code","execution_count":null,"id":"ohPUPez8imvE","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":140475,"status":"ok","timestamp":1684431829948,"user":{"displayName":"Jarek Kazmierczak","userId":"02577063793520863126"},"user_tz":420},"id":"ohPUPez8imvE","outputId":"4fd3420b-947c-4560-fd28-e953703c1ca3"},"outputs":[],"source":["! pip install -U google-cloud-aiplatform\n","! pip install -U langchain\n","! pip install -U python-dateutil\n","! pip install -U newspaper3k"]},{"attachments":{},"cell_type":"markdown","id":"B-mPnZJdiwkg","metadata":{"id":"B-mPnZJdiwkg"},"source":["---\n","\n","#### ⚠️ Do not forget to RESTART THE RUNTIME before continue.\n","\n","---"]},{"attachments":{},"cell_type":"markdown","id":"_ARUa9gEK74l","metadata":{"id":"_ARUa9gEK74l"},"source":["## Configure Google Cloud environment settings\n","\n","Set the following constants to reflect your GCP environment.\n","- `PROJECT_ID`: Your Google Cloud Project ID.\n","- `REGION`: The region to use for Vertex AI"]},{"cell_type":"code","execution_count":null,"id":"uVxFSrppK8Oy","metadata":{"id":"uVxFSrppK8Oy"},"outputs":[],"source":["PROJECT_ID = '<YOUR PROJECT ID HERE>'\n","REGION = 'us-central1'"]},{"attachments":{},"cell_type":"markdown","id":"3eb19a2f","metadata":{},"source":["Initialize Vertex SDK."]},{"cell_type":"code","execution_count":null,"id":"18be86c3","metadata":{},"outputs":[],"source":["import vertexai\n","\n","vertexai.init(project=PROJECT_ID, location=REGION)"]},{"attachments":{},"cell_type":"markdown","id":"aASLzl3H28ay","metadata":{"id":"aASLzl3H28ay"},"source":["## Define custom LangChain tools\n","\n","LangChain tools allow LangChain agents to communicate with other systems. For more information on how to build  and use them, please refer to the [Tools getting started documentation](https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html)\n","\n","\n","This section of the notebook defines two custom tools:\n","- The Google Trends dataset tool allows an agent to retrieve a list of top-ranked search keywords on a given date. The tool retrieves this information from the Google Trends BigQuery dataset.\n","- The GDELT tool allows an agent to retrieve news articles that best match a set of keywords, on a given date, and with the given tone. The tool uses [the GDELT API](https://blog.gdeltproject.org/gdelt-doc-2-0-api-debuts/) to retrieve the articles' metadata and content.\n","\n","There are a few options for implementing LangChain tools, including using the `Tool dataclass`, subclassing the `BaseTool class`, or using the `Tool decorator`. Due to the relatively complex logic, both tools are implemented by subclassing the LangChain BaseTool class.\n"]},{"attachments":{},"cell_type":"markdown","id":"b4f129e3","metadata":{},"source":["### Google Trends dataset tool \n","\n","The tool extracts a list of the most popular search terms on a specific date within the last 30 days. The tool is a wrapper around the Google Trends Bigquery dataset. The tool expects to receive a JSON object as input, with the following format:\n","\n","\n","```\n","{\n","    \"date\": \"\"05-16-2023\"\n","}\n","```\n","\n","Google Trends only stores the top search terms for the previous 30 days, so the date you provide must be within the following range: `[current_date - 30, current_date - 1]`. If you provide a date outside of this range, the tool will return an empty list of keywords.\n","\n","\n","The tool can handle a variety of date formats to account for the different ways that an LLM might return dates.\n"]},{"cell_type":"code","execution_count":null,"id":"ffe6b4a2","metadata":{},"outputs":[],"source":["import json\n","\n","from datetime import date, timedelta, time, datetime\n","from typing import Any, Dict, List, Optional, ClassVar, Tuple\n","from google.cloud import bigquery\n","from dateutil.parser import parse as parse_date\n","from langchain.tools import BaseTool\n","\n","\n","class QueryGoogleTrendsDatasetTool(BaseTool):\n","    name = \"query_google_trends\"\n","    description = \"\"\"Useful for when you need to find top search terms on a given date. \n","    Input is a JSON object that has the field date.\n","    The date must be in the following format: YYYY-MM-DD.  \n","    \"\"\"\n","\n","    client: Any\n","    project_id: str \n","    location: str = 'US'\n","\n","    def _retrieve_top_terms(self, date:str):\n","        \"\"\"Retrieves top terms from BigQuery for a given date.\"\"\"\n","\n","        query = f\"\"\"SELECT term, rank FROM `bigquery-public-data.google_trends.top_terms`\n","            WHERE refresh_date = '{date}'\n","            GROUP BY 1,2\n","                ORDER by rank ASC\n","            \"\"\"\n","        query_job = self.client.query(\n","            query=query,\n","            location=self.location)\n","        df = query_job.to_dataframe()\n","        return df\n","\n","    def _parse_date(self, json_params_str: str):\n","        \"\"\"Retrieves a date from the JSON input parameters\n","        and normalizes it to the format required by BigQuery.\"\"\"\n","\n","        params = json.loads(json_params_str)\n","\n","        if 'date' in params:\n","            try:\n","                dt = parse_date(params['date'])\n","                dt = dt.date()\n","            except:\n","                dt = date.today()\n","        else:\n","            dt = date.today()\n","\n","        if dt >= date.today() or dt <= date.today() - timedelta(days=30):\n","            dt_str = \"\"\n","        else:\n","            dt_str = dt.strftime('%Y-%m-%d')\n","\n","        return dt_str\n","\n","    def _run(self, \n","             json_params_str: str):\n","        \"\"\"Return top search terms as a JSON list.\"\"\"\n","\n","        refresh_date = self._parse_date(json_params_str)\n","        terms = json.dumps([])\n","        if refresh_date:\n","            df = self._retrieve_top_terms(refresh_date)\n","            if not df.empty:\n","                terms = df.loc[0].values[0]\n","                terms = json.dumps(terms.split(' '))\n","\n","        return terms\n","\n","    def _arun(self, json_params: str):\n","        raise NotImplementedError(\"This tool does not support async\")"]},{"attachments":{},"cell_type":"markdown","id":"49de72f0","metadata":{},"source":["Let's run a quick test."]},{"cell_type":"code","execution_count":null,"id":"7624f9ef","metadata":{},"outputs":[],"source":["google_trends_tool = QueryGoogleTrendsDatasetTool(\n","    project_id=PROJECT_ID,\n","    client=bigquery.Client(project=PROJECT_ID)) # type: ignore\n","date_str = (date.today() - timedelta(days=10)).strftime('%Y-%m-%d')\n","input_params = f'{{\"date\": \"{date_str}\"}}'\n","google_trends_tool.run(input_params)"]},{"attachments":{},"cell_type":"markdown","id":"832ecbcf","metadata":{},"source":["### GDELT Search tool \n","\n","The `GDELT Search tool` enables an agent to obtain information about articles that match a set of keywords. The tool takes a JSON object as input, with the following format:\n","\n","\n","```\n","{\n","    \"date\": \"05-16-2023\",\n","    \"keywords\": [\"Real\", \"Madrid\"],\n","    \"tone\": \"positive\"\n","}\n","```\n","\n","The tool will search for articles published between the dates `date - time_window_days` and `date + time_window_days`, where `time_window_days` is a configurable parameter. The `tone` field can be either `positive`, `negative`, or `unknown`. Please refer to the [GDELT documentation](https://blog.gdeltproject.org/gdelt-doc-2-0-api-debuts/#:~:text=theme%3ATERROR-,Tone,-.%20Allows%20you%20to) for more information on the tone setting. We define `positive` as a tone value greater than 5 and `negative` as a tone value less than 5. If the tone field is set to `unknown`, it will not be used in the GDELT API query.\n","\n","Besides the time_window, there are other configuration parameters that control the results, including the maximum number of returned records (`max_records`) and the maximum distance between the keywords in an article (`n_near_words`).\n","\n","The tool returns a text that is a compilation of article titles and article summaries for the found articles.\n","\n","The tool is made up of two components:\n","- A retriever that searches for articles that match the input and retrieves the metadata and content of the articles. It uses the GDELT 2.0 DOC API and is implemented as a [LangChain retriever](https://docs.langchain.com/docs/components/indexing/retriever).\n","- A summarizer that is a [LangChain LLM chain](https://docs.langchain.com/docs/components/chains/llm-chain) that summarizes the content of the articles.\n","\n","The tool first runs the retriever to get a list of LangChain documents with the content and metadata of the articles. It then runs the summarizing chain on each article content to create a list of summaries. Finally, it combines the article titles and the summaries into a single piece of text to return as an output.\n","\n","\n","\n","Let's start by defining the retriever."]},{"cell_type":"code","execution_count":null,"id":"1PWBEo0jJkkV","metadata":{"id":"1PWBEo0jJkkV"},"outputs":[],"source":["import requests\n","from newspaper import Article\n","from newspaper import ArticleException\n","from langchain.schema import BaseRetriever, Document\n","\n","class GDELTRetriever(BaseRetriever):\n","    gdelt_api_url: ClassVar[str]='https://api.gdeltproject.org/api/v2/doc/doc'\n","    mode: str='ArtList'\n","    format: str='json'\n","    max_records: int=10\n","    n_near_words: int=50\n","    source_country: str='US'\n","    source_lang: str='english'\n","    time_window_days: int=3\n","\n","    def _get_articles_info(self, keywords: str, startdatetime: datetime, enddatetime: datetime, tone: str) -> Dict:\n","        \"\"\"Retrieves article links and article metadata from GDELT API.\"\"\"\n","\n","        startdatetime_str = startdatetime.strftime('%Y%m%d%H%M%S')\n","        enddatetime_str = enddatetime.strftime('%Y%m%d%H%M%S')\n","        if tone == 'positive':\n","            tone = 'tone>5'\n","        elif tone == 'negative':\n","            tone = 'tone<-5'\n","        else:\n","            tone = ''\n","\n","        query = f'near{self.n_near_words}:\"{keywords}\" '\n","        query += f'sourcecountry:{self.source_country} sourcelang:{self.source_lang} '\n","        if tone:\n","            query += f'{tone}'\n","        else:\n","            query += query[:-1]\n","        params = {'query': query,\n","                  'format': self.format,\n","                  'mode': self.mode,\n","                  'maxrecords': str(self.max_records),\n","                  'startdatetime': startdatetime_str,\n","                  'enddatetime': enddatetime_str}\n","\n","        response = requests.get(self.gdelt_api_url, params=params)\n","        response.raise_for_status()\n","        return response.json()\n","\n","    def _parse_article(self, url: str) -> str:\n","        \"\"\"Retrieves and scrapes an article from a given URL.\"\"\"\n","        article = Article(url)\n","\n","        try:\n","            article.download()\n","            article.parse()\n","        except ArticleException:\n","            return \"\"\n","        else:\n","            return article.text\n","\n","    def _get_documents(self, articles: Dict) -> List[Document]:\n","        \"\"\"Converts a list of articles into a list of LangChain documents.\"\"\"\n","        documents = []\n","        unique_docs = set()\n","        \n","        if not articles:\n","            return documents\n","\n","        for article in articles['articles']:\n","            parsed_article = self._parse_article(article['url'])\n","            if parsed_article and (article['title'] not in unique_docs):\n","                unique_docs.add(article['title'])\n","                document = Document(\n","                    page_content=parsed_article,\n","                    metadata={\n","                      'title': article['title'],\n","                      'url': article['url'],\n","                      'domain': article['domain'],\n","                      'date': article['seendate']\n","                  }\n","                )\n","                documents.append(document)\n","        return documents\n","\n","    def get_relevant_documents(self, query: str, filters: Optional[Dict[str, object]] = None) -> List[Document]:\n","        \"\"\"Retrieves relevant documents from GDELT API for a given query.\"\"\"\n","\n","        if filters and filters.get('date'):\n","            event_date = filters['date']\n","        else:\n","            event_date = date.today()\n","        if filters and filters.get('tone'):\n","            tone = filters['tone']\n","        else:\n","            tone = ''\n","        startdatetime = datetime.combine(event_date - timedelta(days=self.time_window_days), datetime.min.time())\n","        enddatetime = datetime.combine(event_date + timedelta(days=self.time_window_days), datetime.min.time())\n","        articles = self._get_articles_info(query, startdatetime, enddatetime, tone)\n","        documents = self._get_documents(articles)\n","\n","        return documents\n","\n","    async def aget_relevant_documents(self, query: str) -> List[Document]:\n","        raise NotImplementedError(\"Async interface to GDELT not implemented\")"]},{"attachments":{},"cell_type":"markdown","id":"642187d7","metadata":{},"source":["And run a quick test on it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pprint\n","pp = pprint.PrettyPrinter(indent=4)\n","\n","retriever = GDELTRetriever(max_records=5)\n","\n","keywords = \"Seattle Seahawks\"\n","filters = {\n","    \"date\": date(2022, 2, 2),\n","    \"tone\": \"positive\"\n","}\n","articles = retriever.get_relevant_documents(\n","    query=keywords,\n","    filters=filters\n",")\n","\n","for article in articles:\n","    print(article.page_content[0:300])\n","    pp.pprint(article.metadata)\n","    print('----------------------------')"]},{"attachments":{},"cell_type":"markdown","id":"70d1027a","metadata":{},"source":["We can now define the LangChain tool, which encapsulates the retriever and the summarizer. \n"]},{"cell_type":"code","execution_count":null,"id":"3ed9c842","metadata":{},"outputs":[],"source":["from __future__ import annotations\n","\n","from dateutil.parser import parse as parse_date\n","from langchain.prompts import PromptTemplate\n","from langchain.prompts.base import BasePromptTemplate\n","from langchain.chains.llm import LLMChain \n","from langchain.tools import BaseTool\n","\n","\n","class GDELTSearchTool(BaseTool):\n","    name = \"gdelt_search\"\n","    description = \"\"\"\n","    Useful for when you need to find news or articles matching a list of terms.\n","    Input is a JSON object that has date, keywords, and  tone fields. \n","    The keywords field is a JSON list of terms to use for search.\n","    The date field is a date to use for search. The date format is YYYY-MM-DD.\n","    The tone field can be positive, negative or unknown. If you are not sure what the tone is use unknown.\n","    \"\"\"\n","\n","    failed_to_retrieve_message: str = \"Could not retrieve any articles.\"\n","\n","    gdelt_retriever: GDELTRetriever\n","    summarize_chain: LLMChain\n","    max_words: int = 3000\n","\n","    def _parse_params(self, json_params_str: str) -> [str, dict]:\n","        \"\"\"Parse input parameters.\"\"\"\n","        query = \"\"\n","        filters = {}\n","\n","        params = json.loads(json_params_str)\n","\n","        if ('keywords' in params) and (isinstance(params['keywords'], list)):\n","            query = ' '.join(params['keywords'])\n","\n","        if 'date' in params:\n","            filters['date'] = parse_date(params['date']).date()\n","\n","        if 'tone' in params and params['tone'] in ['positive', 'negative']:\n","            filters['tone'] = params['tone']\n","\n","        return query, filters\n","\n","    def _summarize_articles(self, articles: List[Document]) -> List[str]:\n","        summaries = []\n","        for article in articles:\n","            summary = self.summarize_chain.run(article.page_content[0:self.max_words])       \n","            summaries.append(summary)\n","        return summaries \n","\n","\n","    def _prepare_output(self, articles: List[Document], summaries: List[str]) -> str:\n","        \"\"\"Prepare output returned by the tool.\"\"\"\n","        \n","        response = \"\"\n","        for document, summary in zip(articles, summaries):\n","            record = f\"\"\"\n","            -------------------------------------------------------\n","            Article title: {document.metadata['title']}\n","            Article summary: {summary}\n","            \"\"\"\n","            response += record\n","\n","        return response   \n","    \n","    def _run(self, json_params_str: str):\n","        query, filters = self._parse_params(json_params_str)\n","\n","        if not query:\n","            return self.failed_to_retrieve_message\n","\n","        articles = self.gdelt_retriever.get_relevant_documents(\n","            query=query,\n","            filters=filters\n","        )\n","  \n","        if not articles:\n","            return self.failed_to_retrieve_message\n","        \n","        summaries = self._summarize_articles(articles)\n","        response = self._prepare_output(articles, summaries)\n","\n","        return response\n","\n","    def _arun(self, json_params: str):\n","        raise NotImplementedError(\"This tool does not support async\")"]},{"attachments":{},"cell_type":"markdown","id":"65386673","metadata":{},"source":["Let's create and instance of the tool and run a quick test.\n","\n","First you need to create a summarizing LLMChain."]},{"cell_type":"code","execution_count":null,"id":"a6f290bb","metadata":{},"outputs":[],"source":["from langchain.llms import VertexAI\n","\n","llm = VertexAI(\n","    model_name='text-bison@001',\n","    max_output_tokens=1024,\n","    temperature=0.0,\n","    top_p=0.8,\n","    top_k=40,\n","    verbose=True,\n",")\n","\n","prompt_template = \"\"\"Write a brief summary of the following article:\n","\n","Article:\n","{article}\n","\n","Summary:\n","\"\"\"\n","\n","prompt = PromptTemplate(template=prompt_template, input_variables=[\"article\"])\n","llm_chain = LLMChain(llm=llm, prompt=prompt)"]},{"attachments":{},"cell_type":"markdown","id":"878cd604","metadata":{},"source":["Next, create the instance of the GDELT retriever."]},{"cell_type":"code","execution_count":null,"id":"192b6df7","metadata":{},"outputs":[],"source":["retriever = GDELTRetriever(max_records=5)"]},{"attachments":{},"cell_type":"markdown","id":"c11e4f62","metadata":{},"source":["Use the retriever and the summarizing chain to create an instance of the tool."]},{"cell_type":"code","execution_count":null,"id":"19fca6a3","metadata":{},"outputs":[],"source":["gdelt_tool = GDELTSearchTool(summarize_chain=llm_chain, gdelt_retriever=retriever)"]},{"attachments":{},"cell_type":"markdown","id":"e91204d2","metadata":{},"source":["To run the test let's search for news about Seattle Seahawks that were published around the 3rd of February, 2023, and had a positive tone."]},{"cell_type":"code","execution_count":null,"id":"dadf1058","metadata":{},"outputs":[],"source":["print(gdelt_tool._run('{\"keywords\": [\"Seattle\", \"Seahawks\"], \"date\": \"2023-02-03\", \"tone\": \"positive\"}'))"]},{"attachments":{},"cell_type":"markdown","id":"966cb513","metadata":{},"source":["The tool returned a single piece of text that compiles article titles and article summaries for all matched articles.\n","\n","We now have all the components required to experiment with LangChain agents."]},{"attachments":{},"cell_type":"markdown","id":"L9ArdrBlvz1c","metadata":{"id":"L9ArdrBlvz1c"},"source":["## Experiment with LangChain agents \n","\n","Let's start with a `zero-shot-react-description` agent.\n","\n","A `zero-shot-react-description` agent is the type of an agent that only acts on the current request and has no memory. It is based on the ReAct framework and uses ReAct style prompts when communicating with an LLM. It decides which tool to use to perform an action solely based on the tool's description, so finding the correct description of the tool is critical to the agent's performance.\n","\n","Note:\n","\n","Large language models (LLMs) are not aware of the current date. As a result, if you use relative time references (e.g. yesterday, two todays from now, etc.) in your interactions, they will hallucinate the current date. This can be addressed by configuring the agent to use yet another external tool, but for the purpose of this notebook, we will use absolute date references in the examples.\n"]},{"cell_type":"code","execution_count":null,"id":"f794967d","metadata":{},"outputs":[],"source":["from langchain.agents import initialize_agent\n","from langchain.agents import AgentType\n","\n","tools = [google_trends_tool, gdelt_tool]\n","agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, intermediate_results=True)"]},{"attachments":{},"cell_type":"markdown","id":"8eade551","metadata":{},"source":["Let's display the default prompt that is used by the agent."]},{"cell_type":"code","execution_count":null,"id":"929c839d","metadata":{},"outputs":[],"source":["print(agent.agent.llm_chain.prompt.template)"]},{"attachments":{},"cell_type":"markdown","id":"ae2f4e53","metadata":{},"source":["The prompt, as you can see, merges the tool descriptions from the tools we defined earlier in the notebook with the ReAct style instructions.\n","\n","Let's now run a few queries."]},{"cell_type":"code","execution_count":null,"id":"da4a3337","metadata":{},"outputs":[],"source":["# Google Trends dataset in BigQuery only stores data from the past month.\n","# Change to a valid date.\n","agent(\"What were the top trending news on November 13th 2023?\")"]},{"attachments":{},"cell_type":"markdown","id":"281fa3ff","metadata":{},"source":["The agent utilized the Google Trends tool to obtain the response. Note how the agent properly formatted the input to the tool as a JSON object, in accordance with the tool's instructions.\n","\n","Let's try another question."]},{"cell_type":"code","execution_count":null,"id":"0db98b22","metadata":{},"outputs":[],"source":["agent(\"Get and summarize news articles referring to Seattle Seahawks published on 06-13-2023?\")"]},{"attachments":{},"cell_type":"markdown","id":"af15bae8","metadata":{},"source":["The agent was able to answer this question using the GDELT tool. Once more, notice the correctly formatted JSON input. The agent used the GDELT tool to get summaries of each document and then summarized the articles using the LLM.\n","\n","Let's try a more complex question now.\n"]},{"cell_type":"code","execution_count":null,"id":"0715d481","metadata":{},"outputs":[],"source":["agent(\"Find the news articles for the top trending topics on November 13th.\")"]},{"attachments":{},"cell_type":"markdown","id":"12c98509","metadata":{},"source":["The agent used both the Google Trends and the GDELT tool to answer this question.\n","\n","Now, let's try a composite request combining a question and an imperative instruction."]},{"cell_type":"code","execution_count":null,"id":"72f610e2","metadata":{},"outputs":[],"source":["agent(\"What were the top trending search terms on November 13th, 2023?. Find and summarize the news articles for them\")"]},{"attachments":{},"cell_type":"markdown","id":"c3ed4c93","metadata":{},"source":["### Conversational Agent\n","\n","Another type of LangChain agent is a `conversational-react-description agent`. This agent has a memory that allows it to keep track of the context between multiple questions.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"FpBNupWnJ7Oi","metadata":{"id":"FpBNupWnJ7Oi"},"outputs":[],"source":["from langchain.memory import ConversationBufferMemory\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\")\n","agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)"]},{"attachments":{},"cell_type":"markdown","id":"91ea1547","metadata":{},"source":["Let's display the default prompt used by the agent."]},{"cell_type":"code","execution_count":null,"id":"10e7219d","metadata":{},"outputs":[],"source":["print(agent.agent.llm_chain.prompt.template) # type: ignore"]},{"attachments":{},"cell_type":"markdown","id":"e9ad7a1f","metadata":{},"source":["Let's fix the default prompt to refer to a Google's model."]},{"cell_type":"code","execution_count":null,"id":"6708c22d","metadata":{},"outputs":[],"source":["PREFIX = \"\"\"Assistant is a large language model trained by Google.\n","\n","Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n","\n","TOOLS:\n","------\n","\n","Assistant has access to the following tools:\"\"\"\n","FORMAT_INSTRUCTIONS = \"\"\"To use a tool, please use the following format:\n","\n","```\n","Thought: Do I need to use a tool? Yes\n","Action: the action to take, should be one of [{tool_names}]\n","Action Input: the input to the action\n","Observation: the result of the action\n","```\n","\n","When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n","\n","```\n","Thought: Do I need to use a tool? No\n","{ai_prefix}: [your response here]\n","```\"\"\"\n","\n","SUFFIX = \"\"\"Begin!\n","\n","Previous conversation history:\n","{chat_history}\n","\n","New input: {input}\n","{agent_scratchpad}\"\"\"\n","\n","new_prompt = agent.agent.create_prompt(\n","    tools=tools,\n","    prefix=PREFIX,\n","    suffix=SUFFIX,\n","    format_instructions=FORMAT_INSTRUCTIONS,\n",")\n","\n","agent.agent.llm_chain.prompt = new_prompt\n","\n","print(agent.agent.llm_chain.prompt.template)"]},{"attachments":{},"cell_type":"markdown","id":"0aadf39d","metadata":{},"source":["Let's start with the question about the trending keywords."]},{"cell_type":"code","execution_count":null,"id":"3238f078","metadata":{},"outputs":[],"source":["agent(\"What were the top trending keywords on Novemeber 13th, 2023?\")"]},{"attachments":{},"cell_type":"markdown","id":"707b45ae","metadata":{},"source":["We will now ask a follow-up question that assumes that the agent has already answered the previous question.\n"]},{"cell_type":"code","execution_count":null,"id":"7a3a5a94","metadata":{},"outputs":[],"source":["agent(\"Can you summarize the news articles for them?\")"]},{"attachments":{},"cell_type":"markdown","id":"27398726","metadata":{},"source":["## Review\n","\n","This notebook showed how to use Vertex PaLM text models with LangChain ReAct agents and custom tools. You learned how to:\n","- Create LangChain components like Tools and Retrievers\n","- Configure LangChain zero-shot and conversational agents\n","- Modify the default prompts used by the agents\n","- Interact with agents using both simple and complex queries\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1r8z9S4U1rIC2pVyACYieumrylnLqvEGL","timestamp":1682696524358},{"file_id":"https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook.ipynb","timestamp":1681923907467}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
